{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps only large connected components in the frame\n",
    "def keepLargeComponents(I,th):\n",
    "    R = np.zeros(I.shape)<0\n",
    "    unique_labels = np.unique(I)\n",
    "    for label in unique_labels:\n",
    "        if label == 0:\n",
    "            pass\n",
    "        else:\n",
    "            I2 = I==label\n",
    "            if np.sum(I2)>th:\n",
    "                R = R | I2\n",
    "    return np.float32(255*R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clamp bounding box coordinates\n",
    "def clampBox(bbox, img_shape):\n",
    "    x, y, w, h = bbox\n",
    "    x = max(0, min(x, img_shape[1] - 1))\n",
    "    y = max(0, min(y, img_shape[0] - 1))\n",
    "    w = max(0, min(w, img_shape[1] - x))\n",
    "    h = max(0, min(h, img_shape[0] - y))\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wh(bbox):\n",
    "    x, y, x2, y2 = bbox\n",
    "    w = x2 - x\n",
    "    h = y2 - y\n",
    "    return x, y, w, h\n",
    "\n",
    "def convert_to_x1y1x2y2(bbox):\n",
    "    x, y, w, h = bbox\n",
    "    x2 = x + w\n",
    "    y2 = y + h\n",
    "    return x, y, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves sequence into folder in 'out'\n",
    "def saveSeq(C,counter,th,outputPath):\n",
    "    if len(C)<th:\n",
    "        return\n",
    "\n",
    "    firstFrameOfClip = counter - len(C)\n",
    "\n",
    "    totalDetectionFrames, totalTrackingFrames = 0, 0\n",
    "    trackers = None\n",
    "    consecutivePersonFrames = 1\n",
    "    k = 0\n",
    "    trackingPerson = False\n",
    "    \n",
    "    for frame in C:\n",
    "\n",
    "        # Searches for the next frame with at least one person present\n",
    "        if not trackingPerson or consecutivePersonFrames >= 10: # parameterize tracking frames\n",
    "            # Detects objects\n",
    "            bboxs,labels,conf = cv.detect_common_objects(frame, confidence= 0.4, model='yolov4-tiny')\n",
    "            \n",
    "            # Checks if at least one person is present\n",
    "            person_indices = [i for i, label in enumerate(labels) if label == 'person']\n",
    "            if person_indices:\n",
    "                totalDetectionFrames += 1\n",
    "                trackingPerson = True\n",
    "                consecutivePersonFrames = 1 #???\n",
    "                if len(labels) > 1:\n",
    "                    # Use the indices to filter bboxs, labels, and conf\n",
    "                    bboxs = [bboxs[i] for i in person_indices]\n",
    "                    labels = [labels[i] for i in person_indices]\n",
    "                    conf = [conf[i] for i in person_indices]\n",
    "                  \n",
    "                # Initializes multi-object tracker\n",
    "                trackers = cv2.legacy.MultiTracker_create()\n",
    "                for box in bboxs:\n",
    "                    tracker = cv2.legacy.TrackerCSRT_create()\n",
    "                    box = clampBox(box, frame.shape) # Ensures the bbox is within the image\n",
    "                    trackers.add(tracker, frame, box)\n",
    "            else:\n",
    "                trackingPerson = False\n",
    "                continue # Ignore frames without people\n",
    "        else:\n",
    "            # Updates tracking for each object\n",
    "            totalTrackingFrames += 1\n",
    "            success, newBoxes = trackers.update(frame)\n",
    "            bboxs = []\n",
    "            labels = []  \n",
    "            conf = []\n",
    "            for newBox in newBoxes:\n",
    "                # Convert (x, y, w, h) to (xmin, ymin, xmax, ymax)\n",
    "                x, y, w, h = map(int, newBox)\n",
    "                bbox = (x, y, x + w, y + h)  \n",
    "                bboxs.append(bbox)\n",
    "                labels.append('person') \n",
    "                conf.append(1.0)  # Add a placeholder confidence score\n",
    "            consecutivePersonFrames += 1\n",
    "\n",
    "        k += 1\n",
    "        imName = str(firstFrameOfClip)+'_'+ str(k)+'.jpg'\n",
    "        finalPath = os.path.join(outputPath, imName)\n",
    "        frame = draw_bbox(frame,bboxs,labels,conf)\n",
    "        cv2.imwrite(finalPath,frame)\n",
    "\n",
    "    # print(totalDetectionFrames, totalTrackingFrames, len(C))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaySeq(outPutPath):\n",
    "    for imName in os.listdir(outPutPath):\n",
    "        frame = cv2.imread(os.path.join(outPutPath,imName))\n",
    "        frame = cv2.resize(frame,dsize=(600,400))\n",
    "        cv2.imshow('Display',frame)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame by frame capture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 7\n",
      "0 0 25\n",
      "0 0 28\n",
      "0 0 31\n"
     ]
    }
   ],
   "source": [
    "imPath = r'src/normalFootage'\n",
    "\n",
    "fgModel = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "leastNumOfFrames = 5 # Param?\n",
    "idx = []\n",
    "C = []\n",
    "counter = 0\n",
    "\n",
    "vidName = 'Street'\n",
    "outputPath = os.path.join(os.getcwd(), 'out', vidName) # add ability to name output location\n",
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)\n",
    "\n",
    "for imName in os.listdir(imPath):\n",
    "    counter += 1\n",
    "\n",
    "    frame = cv2.imread(os.path.join(imPath,imName))\n",
    "    frame = cv2.resize(frame,dsize=(600,400))\n",
    "\n",
    "    # Denoises frame\n",
    "    fgmask = fgModel.apply(frame)\n",
    "    K_r = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "    fgmask = cv2.morphologyEx(np.float32(fgmask),cv2.MORPH_OPEN,K_r)\n",
    "\n",
    "    num_labels,labels_im = cv2.connectedComponents(np.array(fgmask>0,np.uint8))\n",
    "    fgmask = keepLargeComponents(labels_im,100) #parameterize in ui\n",
    "\n",
    "    if np.sum(fgmask)>0:\n",
    "        idx.append(counter)\n",
    "        C.append(frame)\n",
    "\n",
    "    # Saves clip during continous changes longer than 2 frames and at least 1 frame away from the last clip\n",
    "    if len(idx) > 2 and idx[-1] > idx[-2]+1: #  or 2\n",
    "        saveSeq(C[:-1],counter,leastNumOfFrames,outputPath)\n",
    "        idx = []\n",
    "        \n",
    "    F = np.zeros(frame.shape,np.uint8)\n",
    "    F[:,:,0],F[:,:,1],F[:,:,2] = fgmask, fgmask,fgmask\n",
    "    F2 = np.hstack((frame,F))\n",
    "    cv2.imshow('Display',F2)\n",
    "\n",
    "    # Break if 'esc' is pressed\n",
    "    k = cv2.waitKey(5) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "saveSeq(C,counter,leastNumOfFrames,outputPath)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Capture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outPutPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m saveSeq(C,counter,leastNumOfFrames,\u001b[43moutPutPath\u001b[49m)\n\u001b[0;32m     47\u001b[0m video\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     48\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outPutPath' is not defined"
     ]
    }
   ],
   "source": [
    "vidPath = r'src\\busyStreet.mp4'\n",
    "video = cv2.VideoCapture(vidPath)\n",
    "\n",
    "fgModel = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "leastNumOfFrames = 5\n",
    "idx = []\n",
    "C = []\n",
    "counter = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    counter += 1\n",
    "\n",
    "    frame = cv2.resize(frame,dsize=(600,400))\n",
    "\n",
    "    # Denoises frame\n",
    "    fgmask = fgModel.apply(frame)\n",
    "    K_r = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "    fgmask = cv2.morphologyEx(np.float32(fgmask),cv2.MORPH_OPEN,K_r)\n",
    "\n",
    "    num_labels,labels_im = cv2.connectedComponents(np.array(fgmask>0,np.uint8))\n",
    "    fgmask = keepLargeComponents(labels_im,100) #parameterize in ui\n",
    "\n",
    "    if np.sum(fgmask)>0:\n",
    "        idx.append(counter)\n",
    "        C.append(frame)\n",
    "\n",
    "    # Saves frame during continous changes longer than 2 frames\n",
    "    if len(idx) > 2 and idx[-1] > idx[-2]+1:\n",
    "        saveSeq(C,counter,leastNumOfFrames,outPutPath)\n",
    "        idx = []\n",
    "        C = []\n",
    "\n",
    "    F = np.zeros(frame.shape,np.uint8)\n",
    "    F[:,:,0],F[:,:,1],F[:,:,2] = fgmask, fgmask,fgmask\n",
    "    F2 = np.hstack((frame,F))\n",
    "    cv2.imshow('Display',F2)\n",
    "\n",
    "    # Break if 'esc' is pressed\n",
    "    k = cv2.waitKey(5) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "saveSeq(C,counter,leastNumOfFrames,outPutPath)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
