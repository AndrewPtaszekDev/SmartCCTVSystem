{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e52502a07641009acd5833032cd30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=5, continuous_update=False, description='Minimum clip length:', layout=Layout(wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Creates sliders \n",
    "minClipLength = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=2,\n",
    "    max=200,\n",
    "    step=1,\n",
    "    description='Minimum clip length:',\n",
    "    continuous_update=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%') \n",
    ")\n",
    "\n",
    "minComponentSize = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=10,\n",
    "    max=800,\n",
    "    step=5,\n",
    "    description='Minimum component size:',\n",
    "    continuous_update=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%') \n",
    ")\n",
    "\n",
    "trackingFrames = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=0,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description='Number of frames to apply tracking:',\n",
    "    continuous_update=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%') \n",
    ")\n",
    "\n",
    "trackingBboxScaleFactor = widgets.FloatSlider(\n",
    "    value=.5,\n",
    "    min=0.1,\n",
    "    max=1,\n",
    "    step=.1,\n",
    "    description='Factor to resize tracking bounding box:',\n",
    "    continuous_update=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%') \n",
    ")\n",
    "\n",
    "# Text input for video path or frame folder path\n",
    "input_path = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter name',\n",
    "    description='Input folder/file name:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Text input for output folder name\n",
    "output_folder = widgets.Text(\n",
    "    value='result',\n",
    "    placeholder='Enter name',\n",
    "    description='Output folder name:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Displays the widgets\n",
    "widget_container = widgets.VBox([\n",
    "    minClipLength, minComponentSize, trackingFrames, trackingBboxScaleFactor, \n",
    "    input_path, output_folder\n",
    "])\n",
    "\n",
    "display(widget_container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps only large connected components in the frame\n",
    "def keepLargeComponents(I,th):\n",
    "    R = np.zeros(I.shape)<0\n",
    "    unique_labels = np.unique(I)\n",
    "    for label in unique_labels:\n",
    "        if label == 0:\n",
    "            pass\n",
    "        else:\n",
    "            I2 = I==label\n",
    "            if np.sum(I2)>th:\n",
    "                R = R | I2\n",
    "    return np.float32(255*R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clamp bounding box coordinates\n",
    "def clampBox(bbox, img_shape):\n",
    "    x, y, w, h = bbox\n",
    "    x = max(0, min(x, img_shape[1] - 1))\n",
    "    y = max(0, min(y, img_shape[0] - 1))\n",
    "    w = max(0, min(w, img_shape[1] - x))\n",
    "    h = max(0, min(h, img_shape[0] - y))\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves sequence into folder in 'out'\n",
    "def saveSeq(C,counter,th,trackingFrames, trackingBboxScaleFactor, outputPath):\n",
    "    if len(C)<th:\n",
    "        return\n",
    "\n",
    "    firstFrameOfClip = counter - len(C)\n",
    "\n",
    "    totalDetectionFrames, totalTrackingFrames = 0, 0\n",
    "    trackers = None\n",
    "    consecutivePersonFrames = 1\n",
    "    k = 0\n",
    "    trackingPerson = False\n",
    "    detection = False\n",
    "    for frame in C:\n",
    "\n",
    "        # Searches for the next frame with at least one person present\n",
    "        if not trackingPerson or consecutivePersonFrames > trackingFrames:\n",
    "            # Detects objects\n",
    "            bboxs,labels,conf = cv.detect_common_objects(frame, confidence= 0.4, model='yolov4-tiny')\n",
    "            \n",
    "            # Checks if at least one person is present\n",
    "            person_indices = [i for i, label in enumerate(labels) if label == 'person']\n",
    "            if person_indices:\n",
    "                totalDetectionFrames += 1\n",
    "                trackingPerson = True\n",
    "                detection = True\n",
    "                consecutivePersonFrames = 1 \n",
    "                if len(labels) > 1:\n",
    "                    # Use the indices to filter bboxs, labels, and conf\n",
    "                    bboxs = [bboxs[i] for i in person_indices]\n",
    "                    labels = [labels[i] for i in person_indices]\n",
    "                    conf = [conf[i] for i in person_indices]\n",
    "                  \n",
    "                # Initializes multi-object tracker\n",
    "                trackers = cv2.legacy.MultiTracker_create()\n",
    "                for box in bboxs:\n",
    "                    tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "                    box = clampBox(box, frame.shape) # Ensures the bbox is within the image\n",
    "\n",
    "                    trackers.add(tracker, frame, box)\n",
    "            else:\n",
    "                trackingPerson = False\n",
    "                continue # Ignores frames without people\n",
    "        else:\n",
    "            # Updates tracking for each object\n",
    "            totalTrackingFrames += 1\n",
    "            success, newBoxes = trackers.update(frame)\n",
    "            bboxs = []\n",
    "            labels = []  \n",
    "            conf = []\n",
    "            for newBox in newBoxes:\n",
    "                # Convert (x, y, w, h) to (xmin, ymin, xmax, ymax)\n",
    "                x, y, w, h = map(int, newBox)\n",
    "                bbox = (x, y, x + int(w*trackingBboxScaleFactor), y + int(h*trackingBboxScaleFactor)) \n",
    "                bboxs.append(bbox)\n",
    "                labels.append('person') \n",
    "                conf.append(1.0)  # Adds a placeholder confidence score\n",
    "            consecutivePersonFrames += 1\n",
    "\n",
    "        k += 1\n",
    "        imName = str(firstFrameOfClip)+'_'+ str(k)+'.jpg'\n",
    "        finalPath = os.path.join(outputPath, imName)\n",
    "        frame = draw_bbox(frame,bboxs,labels,conf, write_conf=detection)\n",
    "        cv2.imwrite(finalPath,frame)\n",
    "        detection = False\n",
    "\n",
    "    print(totalDetectionFrames, totalTrackingFrames, len(C))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaySeq(outPutPath):\n",
    "    for imName in os.listdir(outPutPath):\n",
    "        frame = cv2.imread(os.path.join(outPutPath,imName))\n",
    "        frame = cv2.resize(frame,dsize=(600,400))\n",
    "        cv2.imshow('Display',frame)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame-by-frame capture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisplay\u001b[39m\u001b[38;5;124m'\u001b[39m,F2)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Break if 'esc' key is pressed\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xff\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Checks for valid input/output paths\n",
    "try:\n",
    "    if not output_folder.value or not input_path.value:\n",
    "        raise ValueError(\"Output folder and input path cannot be empty or whitespace\")\n",
    "\n",
    "    outputPath = os.path.join(os.getcwd(), 'out', output_folder.value.strip())\n",
    "    inputPath = os.path.join(os.getcwd(), 'src', input_path.value.strip())\n",
    "\n",
    "    os.makedirs(outputPath, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(inputPath):\n",
    "        raise FileNotFoundError(f\"{inputPath} does not exist\")\n",
    "\n",
    "except (OSError, ValueError) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "imPath = f'src/{input_path.value}'\n",
    "fgModel = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "idx = []\n",
    "C = []\n",
    "counter = 0\n",
    "\n",
    "for imName in os.listdir(imPath):\n",
    "    counter += 1\n",
    "\n",
    "    frame = cv2.imread(os.path.join(imPath,imName))\n",
    "    frame = cv2.resize(frame,dsize=(600,400))\n",
    "\n",
    "    # Denoises frame\n",
    "    fgmask = fgModel.apply(frame)\n",
    "    K_r = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "    fgmask = cv2.morphologyEx(np.float32(fgmask),cv2.MORPH_OPEN,K_r)\n",
    "\n",
    "    # Keeps only large connected components\n",
    "    num_labels,labels_im = cv2.connectedComponents(np.array(fgmask>0,np.uint8))\n",
    "    fgmask = keepLargeComponents(labels_im,minComponentSize.value) \n",
    "\n",
    "    if np.sum(fgmask)>0:\n",
    "        idx.append(counter)\n",
    "        C.append(frame)\n",
    "\n",
    "    # Saves clip during continous changes longer than 2 frames and at least 1 frame away from the last clip\n",
    "    if len(idx) > 2 and idx[-1] > idx[-2]+1:\n",
    "        saveSeq(C[:-1],counter,minClipLength.value, trackingFrames.value, trackingBboxScaleFactor.value, outputPath)\n",
    "        idx = []\n",
    "        C = []\n",
    "    \n",
    "    # Displays original frame alongside masked frame\n",
    "    F = np.zeros(frame.shape,np.uint8)\n",
    "    F[:,:,0],F[:,:,1],F[:,:,2] = fgmask, fgmask,fgmask\n",
    "    F2 = np.hstack((frame,F))\n",
    "    cv2.imshow('Display',F2)\n",
    "\n",
    "    # Break if 'esc' key is pressed\n",
    "    k = cv2.waitKey(5) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "saveSeq(C,counter,minClipLength.value, trackingFrames.value, trackingBboxScaleFactor.value, outputPath)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# On normalFootage (else held standard):\n",
    "\n",
    "# 30 tf, 10.9s\n",
    "# 20 tf, 12.2s\n",
    "# 10 tf, 12.5s\n",
    "# 5 tf, 12.9s\n",
    "# 1 tf, 14.9s\n",
    "# 0 tf, 18.0s\n",
    "\n",
    "# On noisyFootage (150 clip, 600 minCompSize):\n",
    "\n",
    "# 25 tf, 1m, 11.7s\n",
    "# 10 tf, 1m 13.9s\n",
    "# 3 tf, 1m 17.6\n",
    "# 0 tf, 1m 24.4s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outPutPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m saveSeq(C,counter,leastNumOfFrames,\u001b[43moutPutPath\u001b[49m)\n\u001b[0;32m     47\u001b[0m video\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     48\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outPutPath' is not defined"
     ]
    }
   ],
   "source": [
    "vidPath = r'src\\busyStreet.mp4'\n",
    "video = cv2.VideoCapture(vidPath)\n",
    "\n",
    "fgModel = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "leastNumOfFrames = 5\n",
    "idx = []\n",
    "C = []\n",
    "counter = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    counter += 1\n",
    "\n",
    "    frame = cv2.resize(frame,dsize=(600,400))\n",
    "\n",
    "    # Denoises frame\n",
    "    fgmask = fgModel.apply(frame)\n",
    "    K_r = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "    fgmask = cv2.morphologyEx(np.float32(fgmask),cv2.MORPH_OPEN,K_r)\n",
    "\n",
    "    num_labels,labels_im = cv2.connectedComponents(np.array(fgmask>0,np.uint8))\n",
    "    fgmask = keepLargeComponents(labels_im,100) #parameterize in ui\n",
    "\n",
    "    if np.sum(fgmask)>0:\n",
    "        idx.append(counter)\n",
    "        C.append(frame)\n",
    "\n",
    "    # Saves frame during continous changes longer than 2 frames\n",
    "    if len(idx) > 2 and idx[-1] > idx[-2]+1:\n",
    "        saveSeq(C,counter,leastNumOfFrames,outPutPath)\n",
    "        idx = []\n",
    "        C = []\n",
    "\n",
    "    F = np.zeros(frame.shape,np.uint8)\n",
    "    F[:,:,0],F[:,:,1],F[:,:,2] = fgmask, fgmask,fgmask\n",
    "    F2 = np.hstack((frame,F))\n",
    "    cv2.imshow('Display',F2)\n",
    "\n",
    "    # Break if 'esc' is pressed\n",
    "    k = cv2.waitKey(5) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "saveSeq(C,counter,leastNumOfFrames,outPutPath)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
